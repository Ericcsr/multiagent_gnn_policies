[DEFAULT]

alg = pac

# learning parameters
batch_size = 5
buffer_size = 1000
updates_per_step = 200
seed = 12
actor_lr = 5e-5

n_train_episodes = 1000
beta_coeff = 0.995
test_interval = 40
n_test_episodes = 20

# architecture parameters
msg_len = 50
unroll_len = 10
hidden_size = 128
gamma = 0.99
tau = 0.5

# env parameters
env = FlockingRelative-v0
v_max = 3.0
comm_radius = 1.0
n_agents = 100
n_actions = 2
n_states = 6
debug = True
header = reward
dt = 0.01

[test]

fname = dagger_k3