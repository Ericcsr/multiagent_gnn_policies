[DEFAULT]

alg = pac

# learning parameters
batch_size = 10
buffer_size = 1000
updates_per_step = 200
seed = 13
actor_lr = 1e-5
grad_clipping = 0.1

n_train_episodes = 2000
beta_coeff = 0.995
beta_min = 0.5
test_interval = 40
n_test_episodes = 5

# architecture parameters
msg_len = 32
unroll_len = 10
hidden_size = 128
gamma = 0.99
tau = 0.5

# env parameters
env = FlockingRelative-v0
v_max = 3.0
comm_radius = 1.0
n_agents = 100
n_actions = 2
n_states = 6
debug = True
header = reward
dt = 0.01

[test]

fname = dagger_k3